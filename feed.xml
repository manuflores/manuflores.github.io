<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://manuflores.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://manuflores.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-25T23:30:53+00:00</updated><id>https://manuflores.github.io/feed.xml</id><title type="html">blank</title><subtitle># </subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://manuflores.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://manuflores.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://manuflores.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://manuflores.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://manuflores.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://manuflores.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Gershgorin Theorem</title><link href="https://manuflores.github.io/blog/2021/gershgorin-theorem/" rel="alternate" type="text/html" title="Gershgorin Theorem"/><published>2021-11-11T00:00:00+00:00</published><updated>2021-11-11T00:00:00+00:00</updated><id>https://manuflores.github.io/blog/2021/gershgorin-theorem</id><content type="html" xml:base="https://manuflores.github.io/blog/2021/gershgorin-theorem/"><![CDATA[<hr/> <p>layout: distill title: Bounding eigenvalues of a matrix using the Gershgorin disk theorem description: date: 2021-11-11 featured: true</p> <p>authors: - name : Emanuel Flores affiliations: name: Caltech</p> <h1 id="toc">toc:</h1> <h1 id="--name-origins">- name: Origins</h1> <h1 id="-if-a-section-has-subsections-you-can-add-them-as-follows"># if a section has subsections, you can add them as follows:</h1> <h1 id="-subsections"># subsections:</h1> <h1 id="-----name-example-child-subsection-1"># - name: Example Child Subsection 1</h1> <h1 id="-----name-example-child-subsection-2"># - name: Example Child Subsection 2</h1> <h1 id="--name-law-of-large-numbers-and-frequentism">- name: Law of large numbers and frequentism</h1> <h1 id="--name-statistical-mechanics">- name: Statistical mechanics</h1> <h1 id="--name-hilberts-sixth-problem">- name: Hilbert’s sixth problem</h1> <h1 id="--name-axiomatization-in-the-elementary-finite-case">- name: Axiomatization in the “elementary” (finite) case</h1> <h1 id="--name-infinite-families-of-events">- name: Infinite families of events</h1> <h3 id="the-beauty-of-the-gershgorin-disk-theorem">The beauty of the Gershgorin disk theorem</h3> <p>In this post I’ll talk about one of the most beatiful theorems I’ve encountered while studying linear algebra. I bumped into it while taking the ACM104 Applied Linear Algebra course at Caltech, taught by Prof. Kostia Zuev. As the name of the course suggests, this theorem has a lot of applications, one of which we will explore in the end, so if you’re here for the applications, read on! The math can seem a bit hairy if you skim over quickly, but I assure you that it is actually surprisingly simple.</p> <p><em>Disclaimer</em>: The “applications” in the bottom of this post are to understand better certain groups of matrices. For a “real application” of the theorem, in my next post I will use it for an actual algorithm you can use to visualize your data. If you’re more interested in the latter, hang tight.</p> <p>I find this theorem aesthetically pleasing because it has a visual representation. Moreover, I think that the wit with which it came about (by the <a href="https://en.wikipedia.org/wiki/Semyon_Aranovich_Gershgorin">short-lived mathematician Semyon Gershgorin</a>) is to be praised for. It is a clear example of how mathematics are <em>just right there</em>, waiting to be discovered.</p> <p>We follow the proof of the book <em>Applied Linear Algebra</em> by Olver and Shakiban.</p> <h3 id="preliminaries">Preliminaries</h3> <p>Before stating the theorem, we’ll need some definitions. Recall that the magnitude of a complex number \(z = a + ib\) is defined by</p> \[|z| = \sqrt{a^2 + b^2}\] <p>If we define the conjugate, we can compute the magnitude as follows:</p> \[\bar{z} = a - ib, |z|^2 = z \bar{z}\] <p><strong>Definition.</strong> <em>Gershgorin disk</em>. Let \(A \in \mathbb{M}_{n \times n}\) a matrix over \(\mathbb{F}\) (either \(\mathbb{R}\) or \(\mathbb{C}\)).</p> <p>For each \(1 \le i \le n\), define the \(i\)-th Gershgorin disk as :</p> \[\begin{align} D_i = \{ |A_{ii} - z_i | \leq r_i : z \in \mathbb{C} \}\\ r_i = \sum_{j = 1, j \neq i} | A_{ij} | \end{align}\] <p>I know this definition can be not quite intuitive so let me break it down. In words, the i-th Gershgorin disk of a square matrix A is just a closed <a href="https://en.wikipedia.org/wiki/Ball_(mathematics)">ball</a> centered at \(A_{ii}\) with radius equal to the sum of the absolute value of the off-diagonal elements of the i-th row. By construction this ball will live in the complex plane. To keep things simple and start building a mental picture of the theorem, you can think of a single Gershgorin disk as simply a disk or closed ball (a filled circle) in the Cartesian plane.</p> <p><strong>Definition.</strong> <em>Gershgorin domain</em>. The union of the \(n\) Gershgorin disks is the Gershgorin domain.</p> \[\mathfrak{D}_A = \{ \cup_{i = 1}^n D_i \} \subseteq \mathbb{C}\] <p><strong>Definition.</strong> <em>Spectrum of a matrix</em>. We call the spectrum of a matrix A to the set of eigenvalues associated with A. We denote it as \(\mathrm{spec} A\).</p> <h3 id="the-statement">The statement</h3> <p><strong>Theorem.</strong> The spectrum of a matrix A lies within the Gershgorin domain.</p> \[\mathrm{spec A} \subseteq \mathfrak{D}_A \subseteq \mathbb{C}\] <p><em>Proof</em>: The constructive proof is surprisingly straightforward.</p> <p>Let \(\lambda\) be an eigenvalue of A, \(\vec{v}\) be its associated eigenvector. Let \(\vec{u} = \frac{v}{ || v ||_{\infty} }\) be the corresponding unit eigenvector with respect to (w.r.t.) the \(\infty\) norm, i.e.</p> \[|| u ||_\infty = \mathrm{max} \{ |u_1|, ..., |u_n| \} = 1\] <p>Let \(u_i\) be an entry of \(\vec{u}\) that achieves the maximum \(\mid u_i \mid = 1\). Writing out the <em>i</em>-th component of eigenvalue equation we obtain:</p> \[\sum_{j = 1}^ n \mathbf{A}_{ij} u_j = \lambda u_i\] <p>which we can rewrite as:</p> \[\sum_{j \neq i } \mathbf{A}_{ij} u_j = \lambda u_i - \mathbf{A}_{ii} u_i = (\lambda - \mathbf{A}_{ii} ) u_i\] <p>Note: in the last step we just subtracted \(\mathbf{A}_{ii}u_i\) from both sides.</p> <p>Thus, since all \(\mid u_j \mid \le 1\) while \(\mid u_i \mid = 1\) we have that</p> \[\begin{align} |\mathbf{A}_ii - \lambda| &amp;= |\lambda - \mathbf{A}_{ii}| \\ &amp;= |\lambda - \mathbf{A}_{ii}| |u_i|\\ &amp;= | (\lambda - \mathbf{A}_{ii}) u_i | \\ &amp;= | \sum_{j \neq i} \mathbf{A}_{ij} u_j | \\ &amp;\le \sum_{j \neq i } |\mathbf{A}_{ij}| |u_j| \\ &amp;\le \sum_{j \neq i} |\mathbf{A}_{ij}|\\ &amp;= r_i. \end{align}\] <p>We have equality in the third step as can be checked for all cases ( ++, +-, -+, – ). The fourth step is just substituting the equation above. The fifth step holds by the triangle inequality \(||x+y|| \le ||x|| + ||y||\). The sixth line holds as \(|u_j| \le 1 \forall j \neq i\) by construction of \(\vec{u}\).</p> <p>This implies the following:</p> \[|\lambda - \mathbf{A}_{ii}| \le r_i \implies \lambda \in D_i\] <p>An immediate corollary is related to the invertibility of square matrices.</p> <p><strong>Definition.</strong> A square matrix is called diagonally dominant if</p> \[|a_{ii}| &gt; \sum_{j \neq i} |a_{ij}| \forall i = 1, ..., n.\] <p><strong>Corollary.</strong> A strictly diagonally dominant matrix is nonsingular.</p> <p><em>Proof</em>: A matrix is singular iff it admits zero as an eigenvalue (an eigenspace shrinks to zero \(\implies \mathrm{dim }\, \mathrm{ker} \ge 1\). ). Thus, if its Gershgorin domain doesn’t contain zero, it cannot be an eigenvalue, hence A is necessarily invertible / non-singular.</p> <p><strong>Theorem.</strong> A symmetric matrix is positive definite if all of its eigenvalues are positive.</p> <p><strong>Corollary.</strong> A symmetric matrix is positive definite if its Gershgorin domain lies in the positive side of the \(\mathbb{C}\) plane. In other words, a matrix is p.d. if \(a_{ii} &gt; \sum_{j\neq i} a_i \forall i = 1, ..., n.\).</p> <h3 id="examples">Examples</h3> <p><a href="https://colab.research.google.com/github/manuflores/sandbox/blob/master/notebooks/gershgorin.ipynb">Here are some visualizations in a jupyter colab notebook</a> if you want to get a feel of the theorem.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[layout: distill title: Bounding eigenvalues of a matrix using the Gershgorin disk theorem description: date: 2021-11-11 featured: true]]></summary></entry></feed>